---
title: "R Notebook Ladenöffnungszeiten / Einsatzpläne"
output:
  html_document:
    df_print: paged
  df_print: paged
  pdf_document: default
editor_options: 
  chunk_output_type: inline
---
```{r include=FALSE}
# activate install if needed
#install.packages("RPostgreSQL")
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("RColorBrewer")
```

## Libraries installieren

```{r include=FALSE}
require("RPostgreSQL")
library(tidyverse)
library(dplyr)
library(RColorBrewer)
```

## R Objekte

```{r}
items_per_order <- readRDS('./data/products_by_order.rds')
orders <- readRDS('./data/orders.rds')
orders_per_hour_per_day <- readRDS('./data/orders_per_hour_per_day.rds')
products_per_hour_per_day <- readRDS('./data/products_per_hour_per_day.rds')
```

## Bestellungen nach Uhrzeit

Als erstes wäre es interessant zu sehen, wie die Verteilung aller Bestellungen über den Zeitraum von 24 Stunden aussieht, da davon auszugehen ist, dass die Anzahl der Bestellungen pro Uhrzeit variieren. Das folgende Diagramm zeigt die Verteilung aller Bestellungen aus dem Datensatz über 24 Stunden verteilt.

```{r}
orders_per_hour <- orders %>%
  group_by(order_hour_of_day) %>%
  summarise(total_order_count = n())

max_hour <- (orders_per_hour$total_order_count)

ggplot(data = orders_per_hour) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = as.numeric(total_order_count))) + 
  ggtitle("Total Nr of orders per hour") +
  xlab("Order hour") + ylab("Nr of orders") +
  coord_cartesian(ylim=c(0,3650000)) +
  geom_text(aes(x = order_hour_of_day,y = as.numeric(total_order_count), label=as.numeric(total_order_count)), vjust = 0.3, hjust = -0.3, angle = 90)
```  

Aus dem Diagramm ist zu entnehmen, dass Bestellungen 24 Stunden lang pro Tag eingehen. Ab Stunde 6 ist ein Starker Anstieg der eingehenden Produkte bemerkbar bis ca. Stunde 10. Von Stunde 16 bis 0 reduzieren sich die Bestellungen wieder.

<br>
<br>

## Bestellungen nach Wochentag

Es lässt sich ausserdem die Behauptung aufstellen, dass nicht alle Tage gleich viele Personen einkaufen. Tendenziell sollten am Wochenende mehr Personen einkaufen, als unter der Woche. Das folgende Diagramm zeigt alle Bestellungen aus dem Datensatz auf alle Wochendage verteilt.

```{r}
orders_per_day <- orders %>%
  group_by(order_dow) %>%
  summarise(total_order_count = n())

ggplot(data = orders_per_day) + 
  geom_col(mapping = aes(x = order_dow, y = as.numeric(total_order_count), fill = as.factor(order_dow))) +
  ggtitle("Total Nr of orders per Day ") +
  xlab("Order day") + ylab("Nr of orders") +
  labs(fill='Weekday') +
  scale_fill_brewer(palette="Spectral") +
  coord_cartesian(ylim=c(0,8500000)) +
  geom_text(aes(x = order_dow, y = as.numeric(total_order_count), label=as.numeric(total_order_count)), vjust = 0.3, hjust = -0.3, angle = 90)
```

In den Daten gibt es das Attribut order_dow mit den Werten 0 bis 6. Aus dem Diagramm ist zu erkennen, dass an Tag 0 und 1 sichtbar mehr Bestellungen getätigt wurden, als bei den Tagen 2 bis 6. Es lässt sich deshalb vermuten, dass Tag 0 und 1 am Wochenende ist. Leider können wir aus dem Datensatz jedoch nicht eindeutig herauslesen, welche Nummer welchem Wochentag zuzuordnen ist, weshalb wir

<br>
<br>

## Untersuchung der Bestellgrössen.

Falls sehr viele grössere Bestellungen vorhanden sind, können diese den Arbeitsaufwand stark verändern. 

```{r}
mean_order_size <- mean(items_per_order$total_product_count)
median_order_size <- median(items_per_order$total_product_count)
quantile_order_size <- quantile(items_per_order$total_product_count)

ggplot(data = items_per_order) + 
  geom_bar(mapping = aes(x = total_product_count), width=0.9) +
  xlab("Products per order") + ylab("Nr of orders") +
  coord_cartesian(xlim=c(0,75)) +
  ggtitle("Average Nr of products per order") 

```

Das arithmetische Mittel über alle Bestellungen liegt bei `r round((mean_order_size), digits = 2)` verschiedenen Produkten pro Bestellung.

Das Median über alle Bestellungen liegt bei `r median_order_size` verschiedenen Produkten pro Bestellung. Die hälfte aller Bestellungen enthällt entsprechend `r median_order_size` oder Weniger Produkte.

75% aller Bestellungen enthalten `r quantile_order_size[4]` oder weniger unterschiedliche Produkte. 
25% aller Bestellungen enthalten `r quantile_order_size[2]` oder weniger unterschiedliche Produkte. 

Aus der oberen Grafik ist zu sehen, dass es sich eher um kleinere Bestellungen  Handelt. Nehmen wir nun an, dass Persohnen mit bis `r quantile_order_size[2]` verschiedenen Artikeln auch selbständig über einem Self-Check Automat bezahlen würden, könnte so bist 25% der Auslastung an den Kassen "automatisiert werden" 

<br>
<br>

### Maximalwerte einer Stunde

Errechnen der Stunde mit den meisten Bestellungen und mit den meisten Produkte. Diese werden als Referenzwerte für die jeweiligen Auslastungen verwendet.

```{r}
max_products <- products_per_hour_per_day %>%
  summarise(max_day = max(total_product_count)) %>%
  summarise(max_week = max(max_day)) 
max_p <- (max_products$max_week)

max_orders <- orders_per_hour_per_day %>%
  summarise(max_day = max(total_order_count)) %>%
  summarise(max_week = max(max_day)) 
max_o <- (max_orders$max_week)

```

<br>
<br>

### Bestell und Produkteverhältnis

Kreiert eine neue Tabelle. Diese entällt die durchschnittlichen Bestellgrössen, die verhältnismässige Auslastung auf Bestell- und Produkteebene zur Maximalauslastung.

```{r}
order_product_ratio <- orders_per_hour_per_day %>%
  left_join(products_per_hour_per_day, by = c("order_dow" = "order_dow", "order_hour_of_day" = "order_hour_of_day")) %>%
  mutate(order_product_ratio  = total_product_count/total_order_count, workload_orders = total_order_count/max_o, workload_products = total_product_count/max_p)

```


Die grösse der einzelnen Bestellungen beeinflusst direkt den Arbeitsaufwand pro Bestellung.
Ziel: Durchschnittliche Bestellgrössen pro Stunde pro Tag. 

```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = order_product_ratio, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio of products per order")  +
  xlab("Order hour") + ylab("Average order size") +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral") 
  
```

Aus dem folgenden Diagramm ist ersichtlich, dass die Bestellgrösse am Wochentagag 0 um 8:00 Uhr mit durchschnittlich 11.48 verschiedenen items am grössten ist.

Interessant ist, dass die Bestellgrössen über alle Wochentage von 20:00 bis 23:00 im Schnitt um 2 bis 2.5 items pro Bestellung ansteigen. Eine mögliche Erklärung wäre: Da bei instacart online Bestellungen mit home deliveries möglich sind, ein Teil abends nach der Arbeit so den einkauf erledigt.

<br>
<br>

## Auslastung

### Auslastung auf Bestellebene

Im folgenden Diagramm sehen wir die stündliche auslastung auf Bestellebene. Der Wert 1.00 steht für die Stunde mit den meisten Bestellungen. 

```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_orders, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio orders")  +
  xlab("Order hour") + ylab("Relative nr of orders in %") +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```

<br>
<br>

### Auslastung auf Produktebene

Im folgenden Diagramm sehen wir die stündliche auslastung auf Produkteebene. Der Wert 1.00 steht für die Stunde mit den meisten Produkte, welche über die Ladentheke gehen und wird aus der Anzahl Bestellungen/Stunde mal durchschnittliche Bestellgrösse/Stunde errechnet. 

Das Diagramm (Average ratio orders) also kausal zu den Diagrammen (Average ratio orders) und (Average ratio of products per order) 

```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_products, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio products")  +
  xlab("Order hour") + ylab("Relative nr of Products in %") +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```

Da wir keine Angaben zu Produktpreisen oder der Anzahl gleicher Produkte pro wahrenkorb zur Verfügung haben, kömmt die Auslastung auf Produktebene der reellen Auslastung am nächsten.

<br>
<br>

## Verschiedene Schwellenwerte untersuchen

Das folgende Diagramm zeigt nochmals die Auslastung auf Produktebene, dargestellt als Heatmap

```{r}
ggplot(data = order_product_ratio) + 
  geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
  ggtitle("Average ratio of products as heatmap")+
  xlab("Order day") + ylab("Order hour") +
  scale_fill_gradientn(colours=c("#000000","#0000FF","#00FF00","#FFFF00","#FF0000","#990000")) +
  labs(fill='Workload')
```

Wenn wir jetzt annehmen, es lohnt sich erst ab einer gewissen Auslastung zu öffnen, dann können wir nun verschiedene Schwellenwerte untersuchen.

<br>


### Total aller Bestellungen und Produkte

```{r}
Total_products <- sum(order_product_ratio$total_product_count)
Total_orders <- sum(order_product_ratio$total_order_count)
```

<br>

### Referenzwerte für den Dauerbetrieb

```{r}
# Durchgehend Offen:
open_from_0 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.0) 

avg_workload_0 <- mean(open_from_0$workload_products)*100
timesave0 <- open_from_0 %>% 
  summarise(total_hours = n()) 
timesave_0 <- (sum(timesave0$total_hours)/168)*100

P_contains_from_0 <- sum(open_from_0$total_product_count)
P_loss_to_0 <- Total_products - P_contains_from_0

O_contains_from_0 <- sum(open_from_0$total_order_count)
O_loss_to_0 <- Total_orders - O_contains_from_0

P_Percent_loss_0 <- (P_loss_to_0/Total_products)*100
P_Percent_contains_0 <- (P_contains_from_0/Total_products)*100

O_Percent_loss_0 <- (O_loss_to_0/Total_orders)*100
O_Percent_contains_0 <- (O_contains_from_0/Total_orders)*100

open_from_0 <- open_from_0 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```



### Offen ab mindestens 15% Auslastung:

```{r}
open_from_15 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.15) 

final_open_hours <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.15 ) %>%
  filter(workload_products >= 0.17 | order_dow < 2) 

avg_workload_15 <- mean(open_from_15$workload_products)*100
timesave15 <- open_from_15 %>% 
  summarise(total_hours = n()) 
timesave_15 <- (sum(timesave15$total_hours)/168)*100

P_contains_from_15 <- sum(open_from_15$total_product_count)
P_loss_to_15 <- Total_products - P_contains_from_15

O_contains_from_15 <- sum(open_from_15$total_order_count)
O_loss_to_15 <- Total_orders - O_contains_from_15

P_Percent_loss_15 <- (P_loss_to_15/Total_products)*100
P_Percent_contains_15 <- (P_contains_from_15/Total_products)*100

O_Percent_loss_15 <- (O_loss_to_15/Total_orders)*100
O_Percent_contains_15 <- (O_contains_from_15/Total_orders)*100



workplan_15 <-  ggplot(data=open_from_15, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_15 <- open_from_15 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 15 prozentige Auslastung:

`r open_from_15`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_15
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_15, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_15, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_15, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_15/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_15, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 

<br>

### Offen ab mindestens 25% Auslastung:

```{r}
open_from_25 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.25)

avg_workload_25 <- mean(open_from_25$workload_products)*100
timesave25 <- open_from_25 %>% 
  summarise(total_hours = n()) 
timesave_25 <- (sum(timesave25$total_hours)/168)*100

P_contains_from_25 <- sum(open_from_25$total_product_count)
P_loss_to_25 <- Total_products - P_contains_from_25

O_contains_from_25 <- sum(open_from_25$total_order_count)
O_loss_to_25 <- Total_orders - O_contains_from_25

P_Percent_loss_25 <- (P_loss_to_25/Total_products)*100
P_Percent_contains_25 <- (P_contains_from_25/Total_products)*100

O_Percent_loss_25 <- (O_loss_to_25/Total_orders)*100
O_Percent_contains_25 <- (O_contains_from_25/Total_orders)*100



workplan_25 <-  ggplot(data=open_from_25, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_25 <- open_from_25 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 25 prozentige Auslastung:

`r open_from_25`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_25
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_25, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_25, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_25, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_25/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_25, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 

<br>

### Offen ab mindestens 35% Auslastung:

```{r}
open_from_35 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.35) 

avg_workload_35 <- mean(open_from_35$workload_products)*100
timesave35 <- open_from_35 %>% 
  summarise(total_hours = n()) 
timesave_35 <- (sum(timesave35$total_hours)/168)*100

P_contains_from_35 <- sum(open_from_35$total_product_count)
P_loss_to_35 <- Total_products - P_contains_from_35

O_contains_from_35 <- sum(open_from_35$total_order_count)
O_loss_to_35 <- Total_orders - O_contains_from_35

P_Percent_loss_35 <- (P_loss_to_35/Total_products)*100
P_Percent_contains_35 <- (P_contains_from_35/Total_products)*100

O_Percent_loss_35 <- (O_loss_to_35/Total_orders)*100
O_Percent_contains_35 <- (O_contains_from_35/Total_orders)*100



workplan_35 <-  ggplot(data=open_from_35, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_35 <- open_from_35 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 35 prozentige Auslastung:

`r open_from_35`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_35
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_35, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_35, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_35, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_35/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_35, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 

<br>

### Offen ab mindestens 50% Auslastung:

```{r}
open_from_50 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.5)

avg_workload_50 <- mean(open_from_50$workload_products)*100
timesave50 <- open_from_50 %>% 
  summarise(total_hours = n()) 
timesave_50 <- (sum(timesave50$total_hours)/168)*100

P_contains_from_50 <- sum(open_from_50$total_product_count)
P_loss_to_50 <- Total_products - P_contains_from_50

O_contains_from_50 <- sum(open_from_50$total_order_count)
O_loss_to_50 <- Total_orders - O_contains_from_50

P_Percent_loss_50 <- (P_loss_to_50/Total_products)*100
P_Percent_contains_50 <- (P_contains_from_50/Total_products)*100

O_Percent_loss_50 <- (O_loss_to_50/Total_orders)*100
O_Percent_contains_50 <- (O_contains_from_50/Total_orders)*100


workplan_50 <-  ggplot(data=open_from_50, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  

open_from_50 <- open_from_50 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 50 prozentige Auslastung:

`r open_from_50`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_50
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_50, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_50, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_50, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_50/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_50, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 

<br>

### Offen ab mindestens 60% Auslastung:

```{r}
open_from_60 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.6)

avg_workload_60 <- mean(open_from_60$workload_products)*100
timesave60 <- open_from_60 %>% 
  summarise(total_hours = n()) 
timesave_60 <- (sum(timesave60$total_hours)/168)*100

P_contains_from_60 <- sum(open_from_60$total_product_count)
P_loss_to_60 <- Total_products - P_contains_from_60

O_contains_from_60 <- sum(open_from_60$total_order_count)
O_loss_to_60 <- Total_orders - O_contains_from_60

P_Percent_loss_60 <- (P_loss_to_60/Total_products)*100
P_Percent_contains_60 <- (P_contains_from_60/Total_products)*100

O_Percent_loss_60 <- (O_loss_to_60/Total_orders)*100
O_Percent_contains_60 <- (O_contains_from_60/Total_orders)*100


workplan_60 <-  ggplot(data=open_from_60, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  

open_from_60 <- open_from_60 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 
```

Folgende Tage haben während diesem Zeitraum eine 60 prozentige Auslastung:

`r open_from_60`
 
 Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE, , warning=FALSE}
workplan_60
```

Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_60, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_60, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_60, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_60/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_60, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 

<br>

```{r include=FALSE}
open_from_75 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.75) 

avg_workload_75 <- mean(open_from_75$workload_products)*100
timesave75 <- open_from_75 %>% 
  summarise(total_hours = n()) 
timesave_75 <- (sum(timesave75$total_hours)/168)*100

P_contains_from_75 <- sum(open_from_75$total_product_count)
P_loss_to_75 <- Total_products - P_contains_from_75
P_Percent_loss_75 <- (P_loss_to_75/Total_products)*100
P_Percent_contains_75 <- (P_contains_from_75/Total_products)*100

O_contains_from_75 <- sum(open_from_75$total_order_count)
O_loss_to_75 <- Total_orders - O_contains_from_75
O_Percent_loss_75 <- (O_loss_to_75/Total_orders)*100
O_Percent_contains_75 <- (O_contains_from_75/Total_orders)*100
```

```{r include=FALSE}
open_from_99 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.99) 

avg_workload_99 <- mean(open_from_99$workload_products)*100
timesave99 <- open_from_99 %>% 
  summarise(total_hours = n()) 
timesave_99 <- (sum(timesave99$total_hours)/168)*100

P_contains_from_99 <- sum(open_from_99$total_product_count)
P_loss_to_99 <- Total_products - P_contains_from_99
P_Percent_loss_99 <- (P_loss_to_99/Total_products)*100
P_Percent_contains_99 <- (P_contains_from_99/Total_products)*100

O_contains_from_99 <- sum(open_from_99$total_order_count)
O_loss_to_99 <- Total_orders - O_contains_from_99
O_Percent_loss_99 <- (O_loss_to_99/Total_orders)*100
O_Percent_contains_99 <- (O_contains_from_99/Total_orders)*100

```


## Direkter Vergleich

```{r}
ggplot() + 
  geom_line(mapping = aes(x = c(0, 15, 25, 35, 50, 60, 75, 99), y = c(P_Percent_contains_0, P_Percent_contains_15, P_Percent_contains_25, P_Percent_contains_35, P_Percent_contains_50, P_Percent_contains_60, P_Percent_contains_75, P_Percent_contains_99)),color="#FF000099", size = 1) +
  geom_line(mapping = aes(x = c(0, 15, 25, 35, 50, 60, 75, 99), y = c(O_Percent_contains_0, O_Percent_contains_15, O_Percent_contains_25, O_Percent_contains_35, O_Percent_contains_50, O_Percent_contains_60, O_Percent_contains_75, O_Percent_contains_99)), color="#33AA3399", size = 1) +
  geom_line(mapping = aes(x = c(0, 15, 25, 35, 50, 60, 75, 99), y = c(timesave_0, timesave_15, timesave_25, timesave_35, timesave_50, timesave_60, timesave_75, timesave_99)), color="#00000099", size = 1) +
  ggtitle("Relations")  +
  xlab("Opening treshhold") + ylab("Relative Percentage") +
  labs(color='Weekday') +
  geom_text(aes(40, 85, label="Orders"), color="#33AA3399") +
  geom_text(aes(30, 95, label="Products"), color="#FF000099") +
  geom_text(aes(40, 35, label="Open Times"), color="#00000099") 

```

Dieser Graf zeigt wie sich die die Öffnungszeiten, die abgedeckten Bestellungen und die Abgedeckten Produktverkäufe verändern, wenn der Schwellwert ab dem geöffnet ist, angehoben wird. Aus dem Diagramm ist erkennbar, dass eine Öffnungsschwelle von 15% die grösste Zeitersparrnis im Verhältnis zu den verkauften Produkten mit sich führt, weshalb wir diese Variante emfehlen.

```{r eval=FALSE, include=FALSE}
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ggplot() + 
    geom_col(mapping = aes(x = c(0, 15, 25, 35, 50, 60, 75, 99), y = c(O_Percent_contains_0-timesave_0, O_Percent_contains_15-timesave_15, O_Percent_contains_25-timesave_25, O_Percent_contains_35-timesave_35, O_Percent_contains_50-timesave_50, O_Percent_contains_60-timesave_60, O_Percent_contains_75-timesave_75, O_Percent_contains_99-timesave_99)),color="#000000FF", fill="#33AA3399", width=2) +
  ggtitle("Delta between Orders and Open times")  +
  xlab("Opening treshhold in %") + ylab("Delta between Open time and Orders sold in%") +
  geom_segment(aes(x = 0, y = 0, xend = c(0, 15, 25, 35, 50, 60, 75, 99), yend = c(O_Percent_contains_0-timesave_0, O_Percent_contains_15-timesave_15, O_Percent_contains_25-timesave_25, O_Percent_contains_35-timesave_35, O_Percent_contains_50-timesave_50, O_Percent_contains_60-timesave_60, O_Percent_contains_75-timesave_75, O_Percent_contains_99-timesave_99)))

ggplot() + 
    geom_col(mapping = aes(x = c(0, 15, 25, 35, 50, 60, 75, 99), y = c(P_Percent_contains_0-timesave_0, P_Percent_contains_15-timesave_15, P_Percent_contains_25-timesave_25, P_Percent_contains_35-timesave_35, P_Percent_contains_50-timesave_50, P_Percent_contains_60-timesave_60, P_Percent_contains_75-timesave_75, P_Percent_contains_99-timesave_99)),color="#000000FF", fill="#FF000055", width=2) +
  ggtitle("Delta between Products and Open times")  +
  xlab("Opening treshhold in %") + ylab("Delta between Open time and Products sold in%")  +
  geom_segment(aes(x = 0, y = 0, xend = c(0, 15, 25, 35, 50, 60, 75, 99), yend = c(P_Percent_contains_0-timesave_0, P_Percent_contains_15-timesave_15, P_Percent_contains_25-timesave_25, P_Percent_contains_35-timesave_35, P_Percent_contains_50-timesave_50, P_Percent_contains_60-timesave_60, P_Percent_contains_75-timesave_75, P_Percent_contains_99-timesave_99)))
```


<br>
<br>

## Unsere Empfehlung

### Öffnungszeiten

Damit die Ladenöffnungszeiten einigermassen konstannt sind, empfehlen wir an Tag 4 und 6 je noch eine Stunde früher zu schliessen. Daturch ergeben sich anhand der folgenden Tabelle entsprechende Öffnungszeiten:

**Tag 0 bis 1:    Von 7:00 Uhr bis 23:00 Uhr**   
**Tag 2 bis 6:    vON 7:00 Uhr bis 22:00 Uhr**


```{r}
avg_workload <- mean(final_open_hours$workload_products)*100

timesave <- final_open_hours %>% 
  summarise(total_hours = n()) 
timesave_final <- (sum(timesave$total_hours)/168)*100

P_contains_from_final <- sum(final_open_hours$total_product_count)
P_loss_to_final <- Total_products - P_contains_from_final

P_Percent_loss_final <- (P_loss_to_final/Total_products)*100
P_Percent_contains_final <- (P_contains_from_final/Total_products)*100

shiftplan <-  ggplot(data=final_open_hours, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100, digits = -1))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = round(workload_products*100, digits = -1))) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Final shift") +
    scale_fill_gradientn(colours=c("#1E90FF", "#7FFF00", "#7FFF00", "#FFFF00", "#FFFF00", "#FFA54F", "#FFA54F", "#FF4040", "#FF4040")) +
    xlab("Weekday") + ylab("Hour") 

final_open_hours <- final_open_hours %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```


`r final_open_hours`

Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_final, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_final, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Wärend diesen Öffnungszeiten werden **`r round(P_Percent_loss_final, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. Hier besteht einserseits die Möglichkeit, dass diese sich in die Öffnungszeiten verschieben. Andererseits besteht die Gefahr, dass diese  zu konkurierenden Betrieben abwandern. Dieses Risiko wird tendenziell grösser, je kürzer insgesammt geöffnet ist. Bei diesen Zahlen erachten wir dieses Risiko jedoch als überschaubar.

<br>
<br>

### Einsatzplan

Die nachfolgende Tabelle zeigt die ursprüngliche Auslastung wärend den neuen Öffnungszeiten auf 10% gerundet.
Der neue Einsatzatzplan für die Mitarbeiter dieser Tabelle, wobei diese jeweils noch 30 min vor und nach den Öffnungszeiten anwesend sind.

```{r echo=FALSE}
shiftplan
```

Da es im Detailhandel neben Regulären Mitarbeitern auch viele andere, temporäre Arbeitskräfte gibt, verzichten wir hier auf eine konkretere Einteilung in 8 Stunden-Schichten und empfehlen die Anzahl Mitarbeiter der Tabelle entsprechend anzupassen.

Da sich wie schon zuvor erwähnt viele kleinere Bestellungen im Datensatz finden, erachten wir es auch als eine gute Möglichkeit den Bezahlvorgang an den Kassen durch self-pay Möglichkeiten zu ergänzen. Dadurch sollte sich einerseits ein möglicher Anstieg der Auslastung, durch die Verschiebung der Bestellungen aus den nicht abgedeckten Zeiten kompensieren lassen und anderseits je nach dem sogar Kassenpersonal für andere Arbeiten freigeben, ohne dass mehr Mitarbeiter als uhrsprünglich wärend den neuen Öffnungszeiten vorhanden sind.

```{r eval=FALSE, include=FALSE}
#Disconnect from the DB
# close the connection (don't forget to cleanup)
dbDisconnect(con)
dbUnloadDriver(drv)
```


```{r eval=FALSE, include=FALSE}
#Remove Variables from Global Environement
remove(orders_per_hour_per_day_sql)
```


