---
title: "R Notebook LadenÃƒÆ’Ã‚Â¶ffnungszeiten / EinsatzplÃƒÆ’Ã‚Â¤ne"
output:
  html_document:
    df_print: paged
  df_print: paged
  pdf_document: default
editor_options: 
  chunk_output_type: inline
---
#Install packages if necessary
```{r}
# activate install if needed
#install.packages("RPostgreSQL")
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("RColorBrewer")
```

#install libraries
```{r}
require("RPostgreSQL")
library(DBI)
library(tidyverse)
library(dplyr)
library(RColorBrewer)
```

#Create a connection to the Database
```{r}
# define the database connection string
DB_HOST='server2053.cs.technik.fhnw.ch'
DB_PORT = 5432
DB_DBNAME =  'warenkorb_db' # or'bank_db' 
DB_USERNAME = 'db_user'
DB_PASSWORD = 'db_user_pw'

con <- DBI::dbConnect(
  odbc::odbc(),
  Driver   = "PostgreSQL Unicode(x64)",
  Server   = DB_HOST,
  Database = DB_DBNAME,
  UID      = DB_USERNAME,
  PWD      = DB_PASSWORD,
  Port     = DB_PORT)


# load the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# connect to the database
con <- dbConnect(drv, dbname = DB_DBNAME,
                 host = DB_HOST, port = DB_PORT,
                 user = DB_USERNAME, password = DB_PASSWORD)
```


```{r}
orders <- tbl(con,  "orders")
orders_product_prior <- tbl(con,  "orders_product_prior")
orders_product_train <- tbl(con,  "orders_product_train")
orders_product = tbl(con, "orders_product_prior") %>%
  union_all(tbl(con, "orders_product_train"))
```

#Plots (ggplot2)
##Orders over 24 hours

Als erstes wäre es interessant zu sehen, wie die Verteilung aller Bestellungen über den Zeitraum von 24 Stunden aussieht, da davon auszugehen ist, dass die Anzahl der Bestellungen pro uhrzeit variieren. 



```{r}
orders_per_hour_per_day <- orders %>%
  group_by(order_dow, order_hour_of_day) %>%
  summarise(nr_of_orders = as.numeric(n())) %>%
  collect()

  
ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_orders/7)) + 
  ggtitle("Total Nr of orders per hour") +
  xlab("Order hour") + ylab("Nr of orders")


```  
Aus dem Diagramm ist zu entnehmen, dass Bestellungen 24 Stunden lang pro Tag eingehen. Ab 6 Uhr ist ein Starker Anstieg der eingehenden Produkte bemerkbar............



##Orders over 7 days


```{r}

ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_dow, y = nr_of_orders, fill = as.factor(order_dow))) +
  ggtitle("Total Nr of orders per Day ") +
  xlab("Order day") + ylab("Nr of orders") +
  labs(fill='Weekday') +
  scale_fill_brewer(palette="Spectral")
  
```


```{r}
ggplot(data = orders) + 
  geom_boxplot(mapping = aes(x = order_dow, y = order_hour_of_day, group = order_dow, fill = as.factor(order_dow))) + 
  scale_fill_brewer(palette="Spectral") +
  labs(fill='Weekday') +
  ggtitle("Boxplot avg distribution of orders over the days over one week ")
```



##Orders over 24 hours and 7 days
```{r}
ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_orders, fill = as.factor(order_dow))) + 
  facet_wrap(~ order_dow,  nrow = 3) +
  labs(fill='Weekday') +
  scale_fill_brewer(palette="Spectral")
```


##Nr of items per order
Ziel: Untersuchung der Bestellgrössen.

```{r}
#Create a new table with Order_id and nr_of_items per order
items_per_order <- orders_product %>% 
  group_by(orders_id) %>%
  summarise(nr_of_items = as.numeric(max(add_to_cart_order))) 

product_sales_per_week <- orders %>%
  group_by(orders_id) %>%
  left_join(select(items_per_order, orders_id, nr_of_items),by="orders_id")

items_per_order <- items_per_order %>% 
  collect()

ggplot(data = items_per_order) + 
  geom_bar(mapping = aes(x = nr_of_items), width=0.9) +
  xlab("Products per order") + ylab("Nr of orders") +
  coord_cartesian(xlim=c(0,75)) +
  ggtitle("Average Nr of products per order") 

mean_order_size <- mean(items_per_order$nr_of_items)
median_order_size <- median(items_per_order$nr_of_items)
quantile_order_size <- quantile(items_per_order$nr_of_items)
percentages_order_size <- quantile(items_per_order$nr_of_items, c(.10, .20, .30, .40, .50, .60, .70, .80, .90)) 
```
Falls sehr viele grössere Bestellungen vorhanden sind, können diese den Arbeitsaufwand stark verändern. 

Das arithmetische Mittel über alle Bestellungen liegt bei 10.107 verschiedenen Produkten pro Bestellung.

Das Median über alle Bestellungen liegt bei `r median_order_size` verschiedenen Produkten pro Bestellung. Die hälfte aller Bestellungen enthällt entsprechend `r median_order_size` oder Weniger Produkte.

75% aller Bestellungen enthalten `r quantile_order_size[4]` oder weniger unterschiedliche Produkte. 
25% aller Bestellungen enthalten `r quantile_order_size[2]` oder weniger unterschiedliche Produkte. 

Fazit: Aus der oberen Grafik ist zu sehen, dass es sich eher um kleinere Bestellungen bis XYZ verschiedenen Artikeln pro Bestellung Handelt. Nehmen wir nun an, dass Persohnen mit bis `r quantile_order_size[2]` verschiedenen Artikeln auch selbständig über einem Self-Check Automat bezahlen würden, könnte so bist 25% an kassenpersonal eingesparrt werden. Um genauere Aussagen zur individuellen Auslastung machen zu können, müssen erst die durchschnittlichen Bestellgrössen der einzelnen Stunden und Tage Analysiert werden.






##Items over 24 hours and 7 days
```{r}
ggplot(data = product_sales_per_week) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_items, fill = as.factor(order_dow))) +
  facet_wrap(~ order_dow,  nrow = 3) +
  labs(fill='Weekday') +
  xlab("Hour of Day") + ylab("Nr of Items") +
  scale_fill_brewer(palette="Spectral")
```


```{r}
products_per_hour_per_day <- orders %>%
  group_by(order_dow, order_hour_of_day) %>%
  left_join(select(orders_product, orders_id, product_id),by="orders_id") %>%
  summarise(nr_of_products = n()) %>%
  collect()

max_products <- products_per_hour_per_day %>%
  summarise(max_day = max(nr_of_products)) %>%
  summarise(max_week = max(max_day)) 
max_p <- (max_products$max_week)

max_orders <- orders_per_hour_per_day %>%
  summarise(max_day = max(nr_of_orders)) %>%
  summarise(max_week = max(max_day)) 
max_o <- (max_orders$max_week)
```

```{r}

order_product_ratio <- orders_per_hour_per_day %>%
  left_join(products_per_hour_per_day, by = c("order_dow" = "order_dow", "order_hour_of_day" = "order_hour_of_day")) %>%
  mutate(order_product_ratio  = nr_of_products/nr_of_orders, workload_orders = nr_of_orders/max_o, workload_products = nr_of_products/max_p)

```


Aussage: Die grösse der einzelnen Bestellungen beeinflusst direkt den Arbeitsaufwand pro Bestellung
Ziel: Durchschnittliche Bestellgrössen pro Stunde pro Tag. 


Aus dem folgenden Diagramm ist ersichtlich, dass die Bestellgrösse am Wochentagag 0 um 8:00 Uhr mit durchschnittlich 11.48 verschiedenen items am grössten ist.

Interessant ist, dass die Bestellgrössen über alle Wochentage von 20:00 bis 23:00 im Schnitt um 2 bis 2.5 items pro Bestellung ansteigen. Eine mögliche Erklärung wäre: Da bei instacart online Bestellungen mit home deliveries möglich sind, ein Teil abends nach der Arbeit so den einkauf erledigt.


```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = order_product_ratio, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio of products per order")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```



```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_orders, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio orders")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```


```{r}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_products, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average workload")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```

```{r echo=TRUE}
ggplot(data = order_product_ratio) + 
  geom_raster(mapping = aes(x = order_hour_of_day, y = order_dow, fill = workload_products)) +
  ggtitle("Average workload")+
  scale_fill_gradientn(colours=c("#000000","#0000FF","#00FF00","#FFFF00","#FF0000","#990000")) +
  labs(fill='Workload')
```

```{r}
Total_products <- sum(order_product_ratio$nr_of_products)
Total_orders <- sum(order_product_ratio$nr_of_orders)

```

```{r include=FALSE}
open_from_60 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.6)

avg_workload_60 <- mean(open_from_60$workload_products)*100

P_contains_from_60 <- sum(open_from_60$nr_of_products)
P_loss_to_60 <- Total_products - P_contains_from_60

O_contains_from_60 <- sum(open_from_60$nr_of_orders)
O_loss_to_60 <- Total_orders - O_contains_from_60

P_Percent_loss_60 <- (P_loss_to_60/Total_products)*100
P_Percent_contains_60 <- (P_contains_from_60/Total_products)*100

open_from_60 <- open_from_60 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 
```

```{r include=FALSE}
open_from_50 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.5)

avg_workload_50 <- mean(open_from_50$workload_products)*100

P_contains_from_50 <- sum(open_from_50$nr_of_products)
P_loss_to_50 <- Total_products - P_contains_from_50

O_contains_from_50 <- sum(open_from_50$nr_of_orders)
O_loss_to_50 <- Total_orders - O_contains_from_50

P_Percent_loss_50 <- (P_loss_to_50/Total_products)*100
P_Percent_contains_50 <- (P_contains_from_50/Total_products)*100

open_from_50 <- open_from_50 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

```{r include=FALSE}
open_from_35 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.35) 

avg_workload_35 <- mean(open_from_35$workload_products)*100

P_contains_from_35 <- sum(open_from_35$nr_of_products)
P_loss_to_35 <- Total_products - P_contains_from_35

O_contains_from_35 <- sum(open_from_35$nr_of_orders)
O_loss_to_35 <- Total_orders - O_contains_from_35

P_Percent_loss_35 <- (P_loss_to_35/Total_products)*100
P_Percent_contains_35 <- (P_contains_from_35/Total_products)*100

open_from_35 <- open_from_35 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

```{r}
open_from_25 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.25)

avg_workload_25 <- mean(open_from_25$workload_products)*100

P_contains_from_25 <- sum(open_from_25$nr_of_products)
P_loss_to_25 <- Total_products - P_contains_from_25

O_contains_from_25 <- sum(open_from_25$nr_of_orders)
O_loss_to_25 <- Total_orders - O_contains_from_25

P_Percent_loss_25 <- (P_loss_to_25/Total_products)*100
P_Percent_contains_25 <- (P_contains_from_25/Total_products)*100

open_from_25 <- open_from_25 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

```{r}
open_from_15 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.15) 

avg_workload_15 <- mean(open_from_15$workload_products)*100

P_contains_from_15 <- sum(open_from_15$nr_of_products)
P_loss_to_15 <- Total_products - P_contains_from_15

O_contains_from_15 <- sum(open_from_15$nr_of_orders)
O_loss_to_15 <- Total_orders - O_contains_from_15

P_Percent_loss_15 <- (P_loss_to_15/Total_products)*100
P_Percent_contains_15 <- (P_contains_from_15/Total_products)*100

open_from_15 <- open_from_15 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```


##Offen ab mindestens 15% Auslastung:
 
Folgende Tage haben während diesem Zeitraum eine 15 prozentige Auslastung:

`r open_from_15`
 
In diesem Zeitraum gehen nach Datensatz `r round(P_Percent_contains_15, digits = 1)` Prozent aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich `r round(avg_workload_15, digits = 1)` Prozent.

Bei diesen Öffnungszeiten werden `r round(P_Percent_loss_15, digits = 1)` Prozent der Verkauften Produkte im Datensatz nicht abgedeckt. 

Bei den Bestellungen welche ausserhalb der neuen Öffnungszeiten stattfanden, besteht einserseits die Möglichkeit, dass diese sich in die Öffnungszeiten verschieben. Andererseits besteht die Gefahr, dass diese  zu konkurierenden Betrieben abwandern. Dieses Risiko wird tendenziell grösser, je kürzer insgesammt geöffnet ist.


#Disconnect from the DB
```{r eval=FALSE, include=FALSE}
# close the connection (don't forget to cleanup)
dbDisconnect(con)
dbUnloadDriver(drv)
```

#Remove Variables from Global Environement
```{r eval=FALSE, include=FALSE}
remove(orders_per_hour_per_day_sql)
```


