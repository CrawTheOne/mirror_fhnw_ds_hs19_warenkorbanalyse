---
title: "R Notebook Ladenöffnungszeiten / Einsatzpläne"
output:
  html_document:
    df_print: paged
  df_print: paged
  pdf_document: default
editor_options: 
  chunk_output_type: inline
---
#Install packages if necessary
```{r}
# activate install if needed
#install.packages("RPostgreSQL")
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("RColorBrewer")
```

#install libraries
```{r include=FALSE}
require("RPostgreSQL")
library(DBI)
library(tidyverse)
library(dplyr)
library(RColorBrewer)
```

#Create a connection to the Database
```{r include=FALSE}
# define the database connection string
DB_HOST='server2053.cs.technik.fhnw.ch'
DB_PORT = 5432
DB_DBNAME =  'warenkorb_db' # or'bank_db' 
DB_USERNAME = 'db_user'
DB_PASSWORD = 'db_user_pw'

con <- DBI::dbConnect(
  odbc::odbc(),
  Driver   = "PostgreSQL Unicode(x64)",
  Server   = DB_HOST,
  Database = DB_DBNAME,
  UID      = DB_USERNAME,
  PWD      = DB_PASSWORD,
  Port     = DB_PORT)


# load the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# connect to the database
con <- dbConnect(drv, dbname = DB_DBNAME,
                 host = DB_HOST, port = DB_PORT,
                 user = DB_USERNAME, password = DB_PASSWORD)
```

```{r include=FALSE}
orders <- tbl(con,  "orders")
orders_product_prior <- tbl(con,  "orders_product_prior")
orders_product_train <- tbl(con,  "orders_product_train")
orders_product = tbl(con, "orders_product_prior") %>%
  union_all(tbl(con, "orders_product_train"))
```

#Plots (ggplot2)
## Orders over 24 hours

Als erstes wäre es interessant zu sehen, wie die Verteilung aller Bestellungen über den Zeitraum von 24 Stunden aussieht, da davon auszugehen ist, dass die Anzahl der Bestellungen pro Uhrzeit variieren. 



```{r echo=FALSE}
orders_per_hour_per_day <- orders %>%
  group_by(order_dow, order_hour_of_day) %>%
  summarise(nr_of_orders = as.numeric(n())) %>%
  collect()

  
ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_orders/7)) + 
  ggtitle("Total Nr of orders per hour") +
  xlab("Order hour") + ylab("Nr of orders")


```  
Aus dem Diagramm ist zu entnehmen, dass Bestellungen 24 Stunden lang pro Tag eingehen. Ab 6 Uhr ist ein Starker Anstieg der eingehenden Produkte bemerkbar............



## Orders over 7 days

Es lässt sich ausserdem die Behauptung aufstellen, dass nicht alle Tage gleich viele Personen einkaufen. Tendenziell sollten am Wochenende mehr Personen einkaufen, als unter der Woche.

```{r echo=FALSE}

ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_dow, y = nr_of_orders, fill = as.factor(order_dow))) +
  ggtitle("Total Nr of orders per Day ") +
  xlab("Order day") + ylab("Nr of orders") +
  labs(fill='Weekday') +
  scale_fill_brewer(palette="Spectral")
  
```

Aus dem Diagramm ist zu erkennen, dass an Tag 0 und 1 ca. 1/4 mehr Bestellungen getätigt wurden, als bei den Tagen 2 bis 6.

```{r include=FALSE}
ggplot(data = orders) + 
  geom_boxplot(mapping = aes(x = order_dow, y = order_hour_of_day, group = order_dow, fill = as.factor(order_dow))) + 
  scale_fill_brewer(palette="Spectral") +
  labs(fill='Weekday') +
  ggtitle("Boxplot avg distribution of orders over the days over one week ")
```



##Orders over 24 hours and 7 days
```{r eval=FALSE, include=FALSE}
ggplot(data = orders_per_hour_per_day) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_orders, fill = as.factor(order_dow))) + 
  facet_wrap(~ order_dow,  nrow = 3) +
  labs(fill='Weekday') +
  scale_fill_brewer(palette="Spectral")
```


##Nr of items per order
Ziel: Untersuchung der Bestellgrössen.

```{r echo=FALSE}
#Create a new table with Order_id and nr_of_items per order
items_per_order <- orders_product %>% 
  group_by(orders_id) %>%
  summarise(nr_of_items = as.numeric(max(add_to_cart_order))) 

product_sales_per_week <- orders %>%
  group_by(orders_id) %>%
  left_join(select(items_per_order, orders_id, nr_of_items),by="orders_id")

items_per_order <- items_per_order %>% 
  collect()

ggplot(data = items_per_order) + 
  geom_bar(mapping = aes(x = nr_of_items), width=0.9) +
  xlab("Products per order") + ylab("Nr of orders") +
  coord_cartesian(xlim=c(0,75)) +
  ggtitle("Average Nr of products per order") 

mean_order_size <- mean(items_per_order$nr_of_items)
median_order_size <- median(items_per_order$nr_of_items)
quantile_order_size <- quantile(items_per_order$nr_of_items)
percentages_order_size <- quantile(items_per_order$nr_of_items, c(.10, .20, .30, .40, .50, .60, .70, .80, .90)) 
```
Falls sehr viele grössere Bestellungen vorhanden sind, können diese den Arbeitsaufwand stark verändern. 

Das arithmetische Mittel über alle Bestellungen liegt bei 10.107 verschiedenen Produkten pro Bestellung.

Das Median über alle Bestellungen liegt bei `r median_order_size` verschiedenen Produkten pro Bestellung. Die hälfte aller Bestellungen enthällt entsprechend `r median_order_size` oder Weniger Produkte.

75% aller Bestellungen enthalten `r quantile_order_size[4]` oder weniger unterschiedliche Produkte. 
25% aller Bestellungen enthalten `r quantile_order_size[2]` oder weniger unterschiedliche Produkte. 

Fazit: Aus der oberen Grafik ist zu sehen, dass es sich eher um kleinere Bestellungen bis XYZ verschiedenen Artikeln pro Bestellung Handelt. Nehmen wir nun an, dass Persohnen mit bis `r quantile_order_size[2]` verschiedenen Artikeln auch selbständig über einem Self-Check Automat bezahlen würden, könnte so bist 25% der Auslastung an den Kassen "automatisiert werden" 





##Items over 24 hours and 7 days
```{r eval=FALSE, include=FALSE}
ggplot(data = product_sales_per_week) + 
  geom_col(mapping = aes(x = order_hour_of_day, y = nr_of_items, fill = as.factor(order_dow))) +
  facet_wrap(~ order_dow,  nrow = 3) +
  labs(fill='Weekday') +
  xlab("Hour of Day") + ylab("Nr of Items") +
  scale_fill_brewer(palette="Spectral")
```


```{r include=FALSE}
products_per_hour_per_day <- orders %>%
  group_by(order_dow, order_hour_of_day) %>%
  left_join(select(orders_product, orders_id, product_id),by="orders_id") %>%
  summarise(nr_of_products = n()) %>%
  collect()

max_products <- products_per_hour_per_day %>%
  summarise(max_day = max(nr_of_products)) %>%
  summarise(max_week = max(max_day)) 
max_p <- (max_products$max_week)

max_orders <- orders_per_hour_per_day %>%
  summarise(max_day = max(nr_of_orders)) %>%
  summarise(max_week = max(max_day)) 
max_o <- (max_orders$max_week)

mean_products <- products_per_hour_per_day %>%
  summarise(mean_day = mean(nr_of_products)) %>%
  summarise(mean_week = mean(mean_day)) 
mean_p <- (mean_products$mean_week)

mean_orders <- orders_per_hour_per_day %>%
  summarise(mean_day = mean(nr_of_orders)) %>%
  summarise(mean_week = mean(mean_day)) 
mean_o <- (mean_orders$mean_week)
```

```{r include=FALSE}

order_product_ratio <- orders_per_hour_per_day %>%
  left_join(products_per_hour_per_day, by = c("order_dow" = "order_dow", "order_hour_of_day" = "order_hour_of_day")) %>%
  mutate(order_product_ratio  = nr_of_products/nr_of_orders, workload_orders = nr_of_orders/max_o, workload_products = nr_of_products/max_p, mean_workload_orders = nr_of_orders/mean_o, mean_workload_products = nr_of_products/mean_p)

```


Aussage: Die grösse der einzelnen Bestellungen beeinflusst direkt den Arbeitsaufwand pro Bestellung
Ziel: Durchschnittliche Bestellgrössen pro Stunde pro Tag. 


```{r echo=FALSE}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = order_product_ratio, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio of products per order")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```

Aus dem folgenden Diagramm ist ersichtlich, dass die Bestellgrösse am Wochentagag 0 um 8:00 Uhr mit durchschnittlich 11.48 verschiedenen items am grössten ist.

Interessant ist, dass die Bestellgrössen über alle Wochentage von 20:00 bis 23:00 im Schnitt um 2 bis 2.5 items pro Bestellung ansteigen. Eine mögliche Erklärung wäre: Da bei instacart online Bestellungen mit home deliveries möglich sind, ein Teil abends nach der Arbeit so den einkauf erledigt.


```{r echo=FALSE}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_orders, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average ratio orders")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```


```{r echo=FALSE}
ggplot(data = order_product_ratio) + 
  geom_line(mapping = aes(x = order_hour_of_day, y = workload_products, color=as.factor(order_dow), group = order_dow), size = 1) +
  ggtitle("Average workload")  +
  labs(color='Weekday') +
  scale_color_brewer(palette="Spectral")
```

```{r echo=TRUE}
ggplot(data = order_product_ratio) + 
  geom_raster(mapping = aes(x = order_hour_of_day, y = order_dow, fill = workload_products)) +
  ggtitle("Average workload as heatmap")+
  scale_fill_gradientn(colours=c("#000000","#0000FF","#00FF00","#FFFF00","#FF0000","#990000")) +
  labs(fill='Workload')
```

# Conclusion
```{r include=FALSE}
Total_products <- sum(order_product_ratio$nr_of_products)
Total_orders <- sum(order_product_ratio$nr_of_orders)

```

## Durchgehend Offen:
```{r include=FALSE}
open_from_0 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.0) 

avg_workload_0 <- mean(open_from_0$workload_products)*100

P_contains_from_0 <- sum(open_from_0$nr_of_products)
P_loss_to_0 <- Total_products - P_contains_from_0

O_contains_from_0 <- sum(open_from_0$nr_of_orders)
O_loss_to_0 <- Total_orders - O_contains_from_0

P_Percent_loss_0 <- (P_loss_to_0/Total_products)*100
P_Percent_contains_0 <- (P_contains_from_0/Total_products)*100

open_from_0 <- open_from_0 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

## Offen ab mindestens 15% Auslastung:
```{r include=FALSE}
open_from_15 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.15) 

avg_workload_15 <- mean(open_from_15$workload_products)*100
timesave <- open_from_15 %>% 
  summarise(total_hours = n()) 
timesave_15 <- (sum(timesave$total_hours)/168)*100

P_contains_from_15 <- sum(open_from_15$nr_of_products)
P_loss_to_15 <- Total_products - P_contains_from_15

O_contains_from_15 <- sum(open_from_15$nr_of_orders)
O_loss_to_15 <- Total_orders - O_contains_from_15

P_Percent_loss_15 <- (P_loss_to_15/Total_products)*100
P_Percent_contains_15 <- (P_contains_from_15/Total_products)*100


workplan_15 <-  ggplot(data=open_from_15, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_15 <- open_from_15 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

open_from_15


```

Folgende Tage haben während diesem Zeitraum eine 15 prozentige Auslastung:

`r open_from_15`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_15
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_15, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_15, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_15, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_15/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_15, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 



## Offen ab mindestens 25% Auslastung:
```{r include=FALSE}
open_from_25 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.25)

avg_workload_25 <- mean(open_from_25$workload_products)*100
timesave <- open_from_25 %>% 
  summarise(total_hours = n()) 
timesave_25 <- (sum(timesave$total_hours)/168)*100

P_contains_from_25 <- sum(open_from_25$nr_of_products)
P_loss_to_25 <- Total_products - P_contains_from_25

O_contains_from_25 <- sum(open_from_25$nr_of_orders)
O_loss_to_25 <- Total_orders - O_contains_from_25

P_Percent_loss_25 <- (P_loss_to_25/Total_products)*100
P_Percent_contains_25 <- (P_contains_from_25/Total_products)*100


workplan_25 <-  ggplot(data=open_from_25, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_25 <- open_from_25 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 25 prozentige Auslastung:

`r open_from_25`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_25
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_25, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_25, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_25, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_25/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_25, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 



## Offen ab mindestens 35% Auslastung:
```{r include=FALSE}
open_from_35 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.35) 

avg_workload_35 <- mean(open_from_35$workload_products)*100
timesave <- open_from_35 %>% 
  summarise(total_hours = n()) 
timesave_35 <- (sum(timesave$total_hours)/168)*100

P_contains_from_35 <- sum(open_from_35$nr_of_products)
P_loss_to_35 <- Total_products - P_contains_from_35

O_contains_from_35 <- sum(open_from_35$nr_of_orders)
O_loss_to_35 <- Total_orders - O_contains_from_35

P_Percent_loss_35 <- (P_loss_to_35/Total_products)*100
P_Percent_contains_35 <- (P_contains_from_35/Total_products)*100


workplan_35 <-  ggplot(data=open_from_35, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  


open_from_35 <- open_from_35 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 35 prozentige Auslastung:

`r open_from_35`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_35
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_35, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_35, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_35, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_35/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_35, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 



## Offen ab mindestens 50% Auslastung:
```{r include=FALSE}
open_from_50 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.5)

avg_workload_50 <- mean(open_from_50$workload_products)*100
timesave <- open_from_50 %>% 
  summarise(total_hours = n()) 
timesave_50 <- (sum(timesave$total_hours)/168)*100

P_contains_from_50 <- sum(open_from_50$nr_of_products)
P_loss_to_50 <- Total_products - P_contains_from_50

O_contains_from_50 <- sum(open_from_50$nr_of_orders)
O_loss_to_50 <- Total_orders - O_contains_from_50

P_Percent_loss_50 <- (P_loss_to_50/Total_products)*100
P_Percent_contains_50 <- (P_contains_from_50/Total_products)*100


workplan_50 <-  ggplot(data=open_from_50, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  

open_from_50 <- open_from_50 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 

```

Folgende Tage haben während diesem Zeitraum eine 50 prozentige Auslastung:

`r open_from_50`

Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE}
workplan_50
```
 
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_50, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_50, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_50, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_50/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_50, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 



## Offen ab mindestens 60% Auslastung:
```{r include=FALSE}
open_from_60 <- order_product_ratio %>%
  select(-c(order_product_ratio, workload_orders)) %>%
  filter(workload_products >= 0.6)

avg_workload_60 <- mean(open_from_60$workload_products)*100
timesave <- open_from_60 %>% 
  summarise(total_hours = n()) 
timesave_60 <- (sum(timesave$total_hours)/168)*100

P_contains_from_60 <- sum(open_from_60$nr_of_products)
P_loss_to_60 <- Total_products - P_contains_from_60

O_contains_from_60 <- sum(open_from_60$nr_of_orders)
O_loss_to_60 <- Total_orders - O_contains_from_60

P_Percent_loss_60 <- (P_loss_to_60/Total_products)*100
P_Percent_contains_60 <- (P_contains_from_60/Total_products)*100

workplan_60 <-  ggplot(data=open_from_60, aes(x=order_dow, y=order_hour_of_day, label=round(workload_products*100))) + 
    geom_raster(mapping = aes(x = order_dow, y = order_hour_of_day, fill = workload_products)) +
    geom_text() + 
    coord_cartesian(xlim=c(-0.2,6.2), ylim=c(0.5,22.5)) +
    theme(panel.grid.minor = element_line(colour="black", size=0.1), panel.grid.major = element_blank(), panel.ontop = TRUE, panel.background = element_blank(), legend.position = "none") +
    scale_x_continuous(minor_breaks = seq(-0.50 , 6.6, 1), breaks = seq(0,6, 1)) +
    scale_y_continuous(minor_breaks = seq(-0.53 , 23.5, 1), breaks = seq(0,23, 1)) +
    ggtitle("Average workload in %")+
    scale_fill_gradientn(colours=c("#5555FF55")) +
    xlab("Weekday") + ylab("Hour") 
  

open_from_60 <- open_from_60 %>%
  group_by(order_dow) %>%
  summarise(open <- min(order_hour_of_day), close <- max(order_hour_of_day)) 
```

Folgende Tage haben während diesem Zeitraum eine 60 prozentige Auslastung:

`r open_from_60`
 
 Daraus ergiebt sich der Folgende Arbeitsplan:
 
```{r echo=FALSE, , warning=FALSE}
workplan_60
```
Passen wir die Verkaufszeiten der Tabelle entsprechend an, gehen in **`r round(timesave_60, digits = 1)` Prozent** der ursprünglichen Öffnungszeit insgesammt **`r round(P_Percent_contains_60, digits = 1)` Prozent** aller Produkte über die Ladentheke.

Die Auslastung beträgt pro Stunde durchschnittlich **`r round(avg_workload_60, digits = 1)` Prozent** (Gemessen an der Stunde mit der grössten Auslastung = 100%.), was einer Erhöhung von durchschnittlich **`r round((avg_workload_60/avg_workload_0), digits = 1)*100-100` Prozent** pro Stunde entspricht.

Bei diesen Öffnungszeiten werden **`r round(P_Percent_loss_60, digits = 1)` Prozent** der Verkauften Produkte im Datensatz nicht abgedeckt. 



* Zusammenfassung

**Immer offen**

Öffnungszeiten:           100 Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_0, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_0, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_0, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_0/avg_workload_0), digits = 1)*100-100` Prozent verglichen mit 24/7  

**15+ Prozent**

Öffnungszeiten:           `r round(timesave_15, digits = 1)` Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_15, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_15, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_15, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_15/avg_workload_0), digits = 1)*100-100` Prozent verglichen mit 24/7  

**25+ Prozent**

Öffnungszeiten:           `r round(timesave_25, digits = 1)` Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_25, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_25, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_25, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_25/avg_workload_0), digits = 1)*100-100` Prozent verglichen mit 24/7  

**35+ Prozent**

Öffnungszeiten:           `r round(timesave_35, digits = 1)` Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_35, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_35, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_35, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_60/avg_workload_35), digits = 1)*100-100` Prozent verglichen mit 24/7  

**50+ Prozent**

Öffnungszeiten:           `r round(timesave_50, digits = 1)` Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_50, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_50, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_50, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_50/avg_workload_0), digits = 1)*100-100` Prozent verglichen mit 24/7  

**60+ Prozent**

Öffnungszeiten:           `r round(timesave_60, digits = 1)` Prozent von 24/7  
Abgedeckte Produkte:      `r round(P_Percent_contains_60, digits = 1)` Prozent  
Nicht Abgedeckt:          `r round(P_Percent_loss_60, digits = 1)` Prozent  
Ø Auslastung:             `r round(avg_workload_60, digits = 1)` Prozent  
Ø Steigerung Auslastung   `r round((avg_workload_60/avg_workload_0), digits = 1)*100-100` Prozent verglichen mit 24/7  

Wir sehen, dass durch eine Anhebung der Grenze als Öffnungskriterium auf nur 15% Auslastung, bereits eine massive Ersparnis an Öffnungszeit und endsprechend auch Betriebskosten haben.

Bei den Bestellungen welche ausserhalb der neuen Öffnungszeiten stattfanden, besteht einserseits die Möglichkeit, dass diese sich in die Öffnungszeiten verschieben. Andererseits besteht die Gefahr, dass diese  zu konkurierenden Betrieben abwandern. Dieses Risiko wird tendenziell grösser, je kürzer insgesammt geöffnet ist. Wir empfehlen deshalb maximal die 50+ Prozent Variante.

Da sich viele kleinere Bestellungen im Datensatz finden, erachten wir es als eine gute Möglichkeit den Bezahlvorgang an den Kassen durch self-pay möglichkeiten zu ergänzen. Dadurch sollte sich einerseits ein möglicher Anstieg der Auslastung, durch die Verschiebung der Bestellungen aus den nicht abgedeckten Zeiten, kompensieren lassen und je nach dem sogar Kassenpersonal für andere Arbeiten freigeben.



```{r eval=FALSE, include=FALSE}
#Disconnect from the DB
# close the connection (don't forget to cleanup)
dbDisconnect(con)
dbUnloadDriver(drv)
```


```{r eval=FALSE, include=FALSE}
#Remove Variables from Global Environement
remove(orders_per_hour_per_day_sql)
```


